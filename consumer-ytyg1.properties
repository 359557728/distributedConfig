#embedded tomcat server port
server.port=\${port:19930}
#Spring MVC Web Logger的日志级别
logging.level.org.springframework.web=INFO
#业务Logger日志级别
logging.level.com.emarbox=INFO
#Consumer消费的 Kafka Topic
emar.bs.consumer.topic=5010,5011,5020,5030,5040,5050,5060
#Kafka Consumer Group Name
emar.bs.consumer.group.name=yz
#Kafka Broker Address
emar.bs.consumer.metadata.broker.list={cipher}AQBSsK9VPRJc7iQ0JSxuFoV71C87aIZwOnAZEzt+2v/64o/wcPcSmwDuNU7B0eQsX0ZG+4H9EbgJOMZavX+jq5VXmRjKVPhrRgRqGGkqSWcI4wUA8Pv3od++9BhYLDE1IoSYXzSsxg6Jko6NUVi1dfDunao2Rved2lhaDJDSw59uS4U8kJ58yP4/ayr8QmgtyxodzDUQy1NteGpbRCJNRHYrLSrUL2xnBZBtfGldDAmC9Qn893HggpXCO+C1blSPaivtiC7vFepj/5lxuipGqPta0D7xdGBpkDufbtrQB9Qwz2H7/JAKkMj4p29hpOMIMkB4TbxvqqpPLaEHppx139yGoLci/soOgSVUo7VHLG7Ypdswwxmi2VPwK86quMKUjOum+iBxHqRX6GGbOBnDN0iaZN5YQBwqeKC0mCCHjrKiXHq9dNmq/PqdpWgYZGjit1Y=
#Topic-Redis(contains Ip and Port) Mapping
emar.bs.consumer.redis.info={cipher}AQA5Hzitxj5wfDeMuGbRpPAs3ht4DgToPULuhqRtiP5hTs4T+zb+GjsJZvONHRzT+1HrZK7mYsMmBkSn5j6zVDl2Ancaukj3QZssgYBTbWE8mIGhq/S5QQTjHEfQvfMh6nWVKVoq+fu2b+99QvMEhA7a+rSZMjZdbcKZG/URFRF3zKxjryaiRaFqr0OCYOgyX8nduHl6GF5XynRsVGNZEZLWjeEuNviyPiVzCHQ6umkjFV0aBuVkOVluh6keVBGjnOHxyt6cyg/dkt00t5wT/pmhoETYISE8aKdQDdF47hfPsqMwTw7YM0FWR5CPHqKI1z+6eTcLnyFcaPgGqoI4sF49V3o0f+hSJu9OzZsoySshnpzhNbYPcu1LG75V3/TWUs/HW/mLEuznglCXjdMGUDez
#Redis Rpush Key
emar.bs.consumer.redis.key=media_mq
#Retry Interval After First Redis Operation Failed
redis.retry.initial.interval=500
#Max Retry Times After Redis Operation Failed
redis.retry.max.times=2
#Max Jedis Instance Number In Jedis Pool
redis.max.active=500
#Max Idle Jedis Instance Number in Jedis Pool
redis.max.idle=100
#Max Wait Millisecond
redis.max.wait=10
#Connect Timeout
redis.connect.timeout=15000
#Directory Under Which Data Will Be Saved After Redis Operation Retry Reach The Max Retry Times(set by redis.retry.max.times)
emar.log.directory=retry/logs
#File Suffix Used By File Saved Under Directory
emar.log.format=dat
#The period of time in milliseconds after which we force a refresh of metadata even if we haven't seen any partition leadership changes to proactively discover any new brokers or partitions.
metadata.max.age.ms=10000
#Ensure that backpressure signals from downstream subscribers are capped at the provided prefetchRate when propagated upstream, effectively rate limiting the upstream Publisher.
reactor.kakfa.backpressure.rate.limit=40000
